<p align="center">
  <img src="./docs/assets/logo.png" width="250" alt="TextPixs Logo Placeholder"/>
</p>

# ğŸ¨âœ¨ TextPixs: Advancing Text-to-Image Generation through Novel Hybrid Architectures

### <div align="center"> Your Project Status/Affiliation (e.g., FYP 2025) <div>

<div align="center">
  <a href="https://github.com/SyedaAnshrahGillani/TextPixs"><img src="https://img.shields.io/static/v1?label=Project&message=Github&color=blue&logo=github"></a> &ensp;
  <a href="https://arxiv.org/abs/XXXX.XXXXX"><img src="https://img.shields.io/static/v1?label=Paper&message=Arxiv&color=red&logo=arxiv"></a> &ensp;
  <!-- Add more badges as needed, e.g., demo link, Hugging Face Space -->
</div>

<p align="center" border-radius="10px">
  <img src="./docs/assets/teaser.png" width="90%" alt="TextPixs Teaser Image Placeholder"/>
</p>

## Abstract / Executive Summary

**TextPixs** is a pioneering research project focused on advancing the field of text-to-image generation. It aims to develop a novel hybrid AI architecture that enhances image rendering, improves text fidelity, and refines visual quality in generated images. By addressing current limitations such as ambiguity in text prompts, alignment challenges, and the lack of robust loss functions, TextPixs seeks to bridge the gap between textual ideas and compelling visuals. This project contributes to cutting-edge generative AI technology with potential applications in content creation, advertising, and human-computer interaction.

## ğŸ”¥ğŸ”¥ News

- (ğŸ”¥ New) [2025/07/03] README updated to professional standards, inspired by leading research projects.
- (ğŸ”¥ New) [2025/07/03] FYP1 deliverables organized and integrated into the repository.
- [2025/06/30] Initial project setup and repository creation.

## Table of Contents ğŸ“š

- [Abstract / Executive Summary](#abstract--executive-summary)
- [News](#-news)
- [Introduction](#introduction)
- [Features](#features)
- [Technologies Used](#technologies-used)
- [Roadmap](#roadmap)
- [Performance](#performance)
- [Team](#team)
- [FYP1 Deliverables](#fyp1-deliverables)
- [Project Structure](#project-structure)
- [To-Do List](#to-do-list)
- [Contact](#contact)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)
- [Citation](#citation)

## ğŸ’¡ Introduction

**TextPixs** is a dynamic text-to-image generation platform built for users who want quick, compelling visuals. It is a research-based project focused on turning text into vibrant, detailed images, powered by cutting-edge generative AI technology.

The project addresses the significant challenge of accurate image generation and text rendering within images, which currently limits applications in educational tools, design automation, and digital art. Existing issues include ambiguity in text prompts, alignment challenges, and a lack of robust loss functions for text fidelity.

Our primary objectives include:
- Enhancing the rendering of images via text-to-image generation using state-of-the-art techniques.
- Improving text fidelity and visual quality in generated images.
- Developing a novel hybrid architecture with semantic alignment and text rendering loss.

TextPixs intends to bridge the gap between ideas and visuals, providing users with a creative playground for generating, modifying, and refining images. Our purpose is to research and contribute breakthroughs in achieving excellence in text-to-image generation, with a focus on text fidelity improvements to advance applications in content creation, advertising, and human-computer interactions.

## Features ğŸš€

- **Text-to-Image Generation**: Input a description, and TextPixs will create a high-quality image that matches your vision. This feature leverages a hybrid architecture incorporating Generative Adversarial Networks (GANs) with a Generator and Discriminator, and integrates a fine-tuned Stable Diffusion model for robust image synthesis.
- **Image Modifications** (Phase 2): Modify existing images using text prompts for further customization and creativity.
- **Text-to-Video Capabilities** (Future Phase): Generate short videos from descriptive prompts.

## Technologies Used ğŸ›¡ï¸

- **Backend**: Flask, Python (Note: This is based on FYP1 deliverables. Actual implementation details for FYP2 may vary.)
- **Frontend**: React.js, HTML, CSS (Note: This is based on FYP1 deliverables. Actual implementation details for FYP2 may vary.)
- **Database**: PostgreSQL (Note: This is based on FYP1 deliverables. Actual implementation details for FYP2 may vary.)
- **AI/ML Models**: Fine-Tuned Stable Diffusion Model, Generative Adversarial Networks (GANs) with PyTorch.

## Roadmap ğŸ—ºï¸

Our project roadmap is structured into phases, with iterative progress on deliverables:

- **Initiation Phase (July - August 2024)**: Project setup and initial planning.
- **Literature Review (August - September 2024)**: Comprehensive review of existing research.
- **Gap Analysis (September - November 2024)**: Identification of research gaps and unique contributions.
- **Research Design and Planning (November 2024 - January 2025)**: Detailed design of the hybrid architecture and experimental setup.
- **Data Collection (January - April 2025)**: Gathering and preparing datasets for model training.
- **Data Analysis and Interpretation (March - May 2025)**: Analyzing experimental results and drawing conclusions.
- **Drafting Research Paper (November 2024 - May 2025)**: Writing the final research paper.
- **Final Review & Submission on Selected Journal (May - June 2025)**: Preparing for submission to a journal like CVPR.
- **Documentations & FYP Report (June - July 2025)**: Finalizing all project documentation and the FYP report.

## Performance ğŸ“Š

*(This section will be updated with quantitative performance metrics and comparisons against baseline models as the research progresses in FYP2. Examples of metrics may include FID, CLIP Score, and other relevant evaluation criteria for text-to-image generation.)*

| Metric | TextPixs (Current) | Baseline Model A | Baseline Model B |
|---|---|---|---|
| FID (Lower is better) | TBD | TBD | TBD |
| CLIP Score (Higher is better) | TBD | TBD | TBD |
| GenEval (Higher is better) | TBD | TBD | TBD |
| DPG (Higher is better) | TBD | TBD | TBD |

## Team ğŸ‘¥

**Internal Supervisor**: Sir Osama Ahmed Khan
**External Supervisor & Sponsor**: **Mirza Samad Ahmed Baig** (mirzasamadahmedbaig@gmail.com)

**Team Members**:
- **Syeda Anshrah Gillani (Group Leader)** (1337-2021)
- Umema Mujeeb (2396-2021)
- Maheen Ali (1589-2021)

## FYP1 Deliverables ğŸ“¦

The following key deliverables from FYP1 are available in the `docs/fyp1` directory:

- **FYP 1 Details**: `fyp1_details.pdf`
- **Project Plan (Gantt Chart)**: `project_plan.pdf`
- **Gap Analysis**: `gap_analysis.pdf`
- **Demo Notebook**: `demo.ipynb`
- **FYP1 Presentation**: `fyp1_presentation.pptx`
- **Presentation Template**: `presentation_template.pptx`
- **Model Training Recording**: `model_training_recording.mov`
- **Standee Design**: `standee.pdf`
- **Image Asset**: `image.png`

## Project Structure ğŸ“

The repository is organized as follows:

```
TextPixs/
â”œâ”€â”€ docs/                 # Project documentation and deliverables
â”‚   â”œâ”€â”€ assets/           # Images and other assets for README and documentation
â”‚   â””â”€â”€ fyp1/             # Contains all deliverables from FYP1
â”œâ”€â”€ .github/              # GitHub Actions workflows and configurations
â”œâ”€â”€ LICENSE               # Project license
â””â”€â”€ README.md             # This README file
```
*(Note: Additional directories for code (e.g., `src/`, `backend/`, `frontend/`) will be added as the implementation phase of FYP2 progresses.)*

## ğŸ’ª To-Do List

We are actively working on and planning the following:

- [ ] Develop and implement the novel hybrid AI architecture.
- [ ] Conduct extensive experiments to demonstrate improved text fidelity and visual quality.
- [ ] Generate visualizations (e.g., attention heatmaps, comparative analyses).
- [ ] Draft and submit the final research paper to a relevant conference (e.g., CVPR).
- [ ] Implement and integrate the image modification feature (Phase 2).
- [ ] Explore and develop text-to-video capabilities (Future Phase).
- [ ] Refine and optimize model performance for efficiency and quality.
- [ ] Prepare comprehensive documentation and the final FYP report.

## Contact ğŸ“§

For any inquiries or collaborations, please contact:

- **Syeda Anshrah Gillani (Group Leader)**: syedaanshrah16@gmail.com

## Contributing ğŸ¤

We welcome contributions! If youâ€™re interested in improving TextPixs, please fork the repository, create a new branch, and submit a pull request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/your-feature-name`)
3. Commit your changes (`git commit -m 'Add new feature'`)
4. Push to the branch (`git push origin feature/your-feature-name`)
5. Open a pull request

## License ğŸ“œ

Distributed under the MIT License. See `LICENSE` for more information.

## ğŸ¤— Acknowledgements

We extend our gratitude to the following:

- Our supervisors, Sir Osama Ahmed Khan and Mirza Samad Ahmed Baig, for their invaluable guidance and support.
- Mirza Samad Ahmed Baig for his sponsorship and continued commitment to the project.
- All researchers and open-source contributors whose work has inspired and facilitated this project.

## ğŸ“– Citation

If you find this research project helpful, please consider citing our work (details to be provided upon paper submission).

```bibtex
@misc{textpixs_fyp,
      title={TextPixs: Advancing Text-to-Image Generation through Novel Hybrid Architectures},
      author={Gillani, Syeda Anshrah and Mujeeb, Umema and Ali, Maheen},
      year={2025},
      note={Final Year Project, Hamdard University},
      url={https://github.com/SyedaAnshrahGillani/TextPixs}
}
```