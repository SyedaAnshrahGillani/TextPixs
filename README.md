# TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-in-the-Loop Feedback for Accurate Text Rendering

<div align="center">
  <img src="./assets/logo.png" width="900" alt="TextPixs Logo"/>
  
  [![Paper](https://img.shields.io/badge/arXiv-2025-red.svg?logo=arxiv)](https://arxiv.org/abs/XXXX.XXXXX)
  [![Project](https://img.shields.io/badge/GitHub-Project-blue.svg?logo=github)](https://github.com/SyedaAnshrahGillani/TextPixs)
  [![Demo](https://img.shields.io/badge/ğŸ¤—-Demo-yellow.svg)](https://huggingface.co/spaces/SyedaAnshrahGillani/TextPixs)
  [![License](https://img.shields.io/badge/License-MIT-green.svg)](./LICENSE)
  [![Python](https://img.shields.io/badge/Python-3.8+-blue.svg?logo=python)](https://python.org)
  [![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg?logo=pytorch)](https://pytorch.org)
  
  **A Revolutionary Text-to-Image Framework for Accurate and Legible Text Rendering**
  
  [ğŸ“„ Paper](https://arxiv.org/abs/XXXX.XXXXX) â€¢ [ğŸ¤— Demo](https://huggingface.co/spaces/SyedaAnshrahGillani/TextPixs) â€¢ [ğŸ“š Documentation](./docs/) â€¢ [ğŸš€ Quick Start](#-quick-start)
</div>

---

## ğŸ¯ **TL;DR**

**TextPixs** revolutionizes text-to-image generation by solving the critical challenge of accurate text rendering in AI-generated images. Our framework achieves **75.4% exact match accuracy** through novel dual-stream processing, character-aware attention, and OCR-in-the-loop feedback.

<div align="center">
  <img src="./assets/teaser.png" width="90%" alt="TextPixs showcases superior text rendering capabilities"/>
</div>

## ğŸ“‹ **Table of Contents**

- [ğŸ”¥ News & Updates](#-news--updates)
- [ğŸ’¡ Introduction](#-introduction)
- [ğŸ† Performance](#-performance)
- [ğŸ”¬ Key Innovations](#-key-innovations)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ‹ï¸ Training](#ï¸-training)
- [ğŸ“ Repository Structure](#-repository-structure)
- [ğŸ”® Future Directions](#-future-directions)
- [ğŸ“– Citation](#-citation)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ™ Acknowledgements](#-acknowledgements)

## ğŸ”¥ **News & Updates**

> **Latest Updates** - Stay tuned for the most recent developments

| Date | Update |
|------|--------|
| ğŸ”¥ **2025/07/07** | **Research Paper Submitted!** Our work has been submitted to ArXiv |
| ğŸ”¥ **2025/07/05** | **Project Documentation Added!** Comprehensive documentation now available |
| ğŸ”¥ **2025/06/20** | **Gradio Demo Added!** Interactive demo showcasing TextPixs capabilities |
| ğŸ”¥ **2025/06/01** | **GCDA Introduced!** Novel Glyph-Conditioned Diffusion with Character-Aware Attention |
| ğŸ”¥ **2024/10/27** | **TextPixs is born!** Initial commit and project setup |

## ğŸ’¡ **Introduction**

### The Problem
Modern text-to-image generation models struggle with accurate text rendering, producing blurry, distorted, or illegible text that limits their practical applications in advertising, design, and education.

### Our Solution
**TextPixs** introduces a revolutionary framework that addresses these limitations through three core innovations:

| Innovation | Description | Impact |
|------------|-------------|--------|
| **ğŸ”„ Dual-Stream Text Encoder** | Processes both semantic meaning and visual characteristics of text | Enhanced text understanding |
| **ğŸ‘ï¸ Character-Aware Attention** | Ensures individual characters are rendered clearly without distortion | Crisp character rendering |
| **ğŸ” OCR-in-the-Loop Feedback** | Integrated OCR system reviews and refines generated text for accuracy | Real-time quality assurance |

<div align="center">
  <img src="./assets/results.png" width="90%" alt="TextPixs generates high-quality images with accurate text rendering"/>
</div>

## ğŸ† **Performance**

### Benchmark Results

Our comprehensive evaluation demonstrates TextPixs' superior performance across key metrics:

<div align="center">

| Model | FID â†“ | CER â†“ | WER â†“ | Exact Match (%) â†‘ |
|-------|-------|-------|-------|-------------------|
| DALL-E 2 | 13.9 | 0.45 | 0.58 | 18.5 |
| Stable Diffusion 1.5 | 15.2 | 0.65 | 0.82 | 5.2 |
| TextDiffuser-2 | 14.1 | 0.14 | 0.25 | 60.1 |
| **TextPixs (Ours)** | **14.3** | **0.08** | **0.15** | **75.4** ğŸ† |

</div>

### Key Achievements

- **ğŸ¯ 75.4% Exact Match**: Highest accuracy in text rendering among all evaluated models
- **ğŸ“‰ 0.08 CER**: Lowest Character Error Rate, ensuring precise character recognition
- **ğŸ“Š 0.15 WER**: Minimal Word Error Rate for comprehensive text accuracy
- **âš¡ Real-time Performance**: Efficient inference suitable for production environments

<div align="center">
  <img src="./assets/GCDA Performance Breakthrough - Figure 9 from research paper.png" width="90%" alt="Performance breakthrough visualization"/>
</div>

## ğŸ”¬ **Key Innovations**

### 1. Dual-Stream Architecture
Our dual-stream text encoder processes textual information through two parallel pathways:

<div align="center">
  <img src="./assets/Single Stream vs Dual Stream.png" width="90%" alt="Comparison between single-stream and dual-stream architectures"/>
</div>

### 2. Character-Aware Attention Mechanism
Addressing the fundamental challenge of character merging in attention mechanisms:

<div align="center">
  <img src="./assets/Attention Problem - why characters merge.png" width="90%" alt="Analysis of attention problems in character rendering"/>
</div>

### 3. Segregation Loss Function
Our novel loss function prevents character degradation during training:

<div align="center">
  <img src="./assets/Without and with segregation loss.png" width="90%" alt="Impact of segregation loss on text quality"/>
</div>

## ğŸš€ **Quick Start**

### Prerequisites

```bash
Python >= 3.8
PyTorch >= 2.0
CUDA >= 11.0 (for GPU acceleration)
```

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/SyedaAnshrahGillani/TextPixs.git
cd TextPixs
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Run the Gradio demo**
```bash
cd app
python app_textpixs.py
```

### Basic Usage

```python
from textpixs_pipeline import TextPixsPipeline

# Initialize the pipeline
pipeline = TextPixsPipeline.from_pretrained("textpixs-base")

# Generate image with text
prompt = "A beautiful sunset with the text 'Hello World' written in the sky"
image = pipeline(prompt).images[0]

# Save the result
image.save("output.png")
```

### Advanced Configuration

```python
# Custom generation parameters
image = pipeline(
    prompt=prompt,
    num_inference_steps=50,
    guidance_scale=7.5,
    height=512,
    width=512,
    ocr_feedback=True,  # Enable OCR-in-the-loop
    character_attention=True  # Enable character-aware attention
).images[0]
```

## ğŸ‹ï¸ **Training**

### Data Preparation

Organize your training data in the following structure:

```
asset/example_data/
â”œâ”€â”€ AAA.txt          # Text annotation
â”œâ”€â”€ AAA.png          # Corresponding image
â”œâ”€â”€ BCC.txt          # Text annotation
â”œâ”€â”€ BCC.png          # Corresponding image
â””â”€â”€ ...
```

### Training Configuration

```bash
bash train_scripts/train.sh \
  configs/textpixs_config.yaml \
  --data.data_dir="asset/example_data" \
  --train.train_batch_size=32 \
  --train.learning_rate=1e-4 \
  --train.num_epochs=100
```

### Custom Training

```python
from textpixs_trainer import TextPixsTrainer

trainer = TextPixsTrainer(
    model_config="configs/textpixs_config.yaml",
    data_dir="asset/example_data",
    output_dir="./checkpoints",
    batch_size=32,
    learning_rate=1e-4
)

trainer.train()
```

## ğŸ“ **Repository Structure**

```
TextPixs/
â”œâ”€â”€ ğŸ“ app/                    # Core application and demo
â”‚   â”œâ”€â”€ app_textpixs.py        # Main Gradio application
â”‚   â”œâ”€â”€ textpixs_pipeline.py   # TextPixs diffusion pipeline
â”‚   â”œâ”€â”€ safety_check.py        # Content safety checker
â”‚   â””â”€â”€ *.md                   # Documentation files
â”œâ”€â”€ ğŸ“ assets/                 # Images and visual assets
â”œâ”€â”€ ğŸ“ configs/                # Model and training configurations
â”œâ”€â”€ ğŸ“ docs/                   # Comprehensive documentation
â”‚   â”œâ”€â”€ FYP-Proposal/          # Project proposal documents
â”‚   â”œâ”€â”€ FYP1-Deliverables/     # First phase deliverables
â”‚   â””â”€â”€ FYP2-Deliverables/     # Second phase deliverables
â”œâ”€â”€ ğŸ“ train_scripts/          # Training scripts and utilities
â”œâ”€â”€ ğŸ“ .github/                # GitHub workflows and configurations
â”œâ”€â”€ ğŸ“‹ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“„ LICENSE                 # Project license
â””â”€â”€ ğŸ“– README.md               # This file
```

## ğŸ”® **Future Directions**

Our research opens exciting avenues for future exploration:

<div align="center">
  <img src="./assets/Future Research Directions Enabled by GCDA.png" width="90%" alt="Future research directions visualization"/>
</div>

### Roadmap

- [ ] **ğŸŒ Multi-language Support** - Extend to non-Latin scripts
- [ ] **ğŸ¬ Video Generation** - Apply techniques to video synthesis
- [ ] **ğŸ“± Mobile Optimization** - Lightweight models for mobile deployment
- [ ] **ğŸ¨ Style Transfer** - Incorporate artistic text styles
- [ ] **ğŸ” Real-time Editing** - Interactive text editing capabilities

## ğŸ“– **Citation**

If you find TextPixs useful in your research, please cite our work:

```bibtex
@article{gillani2025textpixs,
  title={TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-in-the-Loop Feedback for Accurate Text Rendering},
  author={Gillani, Syeda Anshrah and Baig, Mirza Samad Ahmed and Khan, Osama Ahmed and Shah, Shahid Munir and Mujeeb, Umema and Ali, Maheen},
  journal={arXiv preprint (coming soon)},
  year={2025}
}
```

## ğŸ¤ **Contributing**

We welcome contributions from the research community! Please see our [Contributing Guidelines](./CONTRIBUTING.md) for details.

### How to Contribute

1. **ğŸ´ Fork** the repository
2. **ğŸŒ¿ Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **ğŸ’¾ Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **ğŸ“¤ Push** to the branch (`git push origin feature/amazing-feature`)
5. **ğŸ”„ Open** a Pull Request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/your-username/TextPixs.git

# Install development dependencies
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install
```

## ğŸ™ **Acknowledgements**

We extend our gratitude to the following projects and individuals:

### ğŸ”¬ **Research Foundations**
- [PixArt-Î±](https://github.com/PixArt-alpha/PixArt-alpha) - Foundational diffusion architecture
- [Diffusers](https://github.com/huggingface/diffusers) - Diffusion model implementations

### ğŸ‘¥ **Core Contributors**

| Contributor | Role | GitHub |
|------------|------|--------|
| **Syeda Anshrah Gillani** | Group Lead | [@SyedaAnshrahGillani](https://github.com/SyedaAnshrahGillani) |
| **Mirza Samad Ahmed Baig** | External Supervisor & Sponsor | |
| **Osama Ahmed Khan** | Internal Supervisor | |
| **Shahid Munir Shah** | Co-Supervisor | |
| **Umema Mujeeb** | Research Assistant | |
| **Maheen Ali** | Research Assistant | |

### ğŸ›ï¸ **Institutional Support**
We thank our institution for providing the computational resources and research environment that made this work possible.

---

<div align="center">
  <p>
    <strong>TextPixs</strong> - Revolutionizing Text-to-Image Generation<br>
    Made with â¤ï¸ by the TextPixs Team
  </p>
  
  <p>
    <a href="https://github.com/SyedaAnshrahGillani/TextPixs">â­ Star</a> â€¢
    <a href="https://github.com/SyedaAnshrahGillani/TextPixs/issues">ğŸ› Report Bug</a> â€¢
    <a href="https://github.com/SyedaAnshrahGillani/TextPixs/issues">ğŸ’¡ Request Feature</a>
  </p>
</div>
